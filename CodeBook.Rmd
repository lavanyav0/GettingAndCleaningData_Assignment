---
title: "CodeBook for Assignment in Getting and Cleaning Data Course"
author: "Lavanya Viswanathan"
date: "April 14, 2017"
output: 
  html_document: 
    keep_md: yes
---

## Assignment Summary

The peer graded assignment in the Coursera course, "Getting and Cleaning Data" requires us to demonstrate that we can download and combine data from different pieces in the provided input, add meaningful column names and metrics, and create a tidy data set as the output.

These files have been submitted for the assignment:

1) run_analysis.R - has the R code for the assignment

2) CodeBook.Rmd for knitr in R studio to generate CodeBook.md and Codebook.html - this is the document you are reading now, that describes what was done for this assignment

3) README.md - because the assignment requires it, but which points to this page

4) out_mean_data.txt - which contains the output tidy data set for this assignment

5) features_info.txt - this was included in the downloaded input and has the best explanation of the meaning of the accelerometer and gyroscope variables in the output tidy data set. It is included here for completeness

## Read and concatenate the raw training and test data sets

The first step is to read the input data set after downloading it using the instructions given on the course website. As per the instructions provided in the README.txt file in the zip file, readings from the sensor signals (accelerometer and gyroscope) are stored in X_train.txt and X_test.txt. The combined raw dataset has 10299 rows and 561 columns, but it has no information telling us which subjects or activities each row corresponds to, or what the column names (variables) are.

```{r read_data,echo=TRUE}
library(plyr)
library(dplyr)
raw_x_train <- read.table("UCI HAR Dataset/train/X_train.txt")
raw_x_test <- read.table("UCI HAR Dataset/test/X_test.txt")
raw_x <- rbind(raw_x_train,raw_x_test)
dim(raw_x)
```

## Load only mean and standard deviation measurements, and label the data set with descriptive variable names

To assign meaningful variable names, we have to load the column names from features.txt. A regular expression search allows us to keep only the measurements that correspond to mean and standard deviations. The resulting data set (x) now has descriptive column names, that are consistent with the long form of the original naming convention in the features_info.txt in the input download. Note that the assignment rubric allows us to keep the long form of these variable names.

The data set at this stage still has 10299 rows, but only 66 columns.

``` {r mean_std_cols,echo=TRUE}
features <- read.table("UCI HAR Dataset/features.txt")
mean_std_features_id <- grep("mean[[:punct:](]|std",features$V2)
mean_std_features <- features$V2[mean_std_features_id]
mean_std_features <- sapply(mean_std_features,function(x) gsub("__","",gsub("___","_",gsub("[[:punct:]()]","_",x))))
x <- raw_x[,mean_std_features_id]
names(x) <- mean_std_features
dim(x)
```


## Add subject and activity

Now it's time to add information on which subject and activities each row in the data set corresponds to. 

First, we read the subject ids for each row from the subject_train.txt and subject_test.txt files. There are 30 subjects in this experiment, so we check that there are 30 unique subject ids in this column

``` {r subject,echo=TRUE}
## read subject id for each row
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt")
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt")
subject <- rbind(subject_train,subject_test)
names(subject) <- c("subject")
unique(subject) %>% arrange(subject)
```

Activities have to be added in two steps. The activity ids for each row are in y_train.txt and y_test.txt. This has to be joined with the map from activity id to activity name in activity_labels.txt. After the join, we check that there are six unique activity ids and activity names.

``` {r activity,echo=TRUE}
## read activity_id and activity_name
raw_y_train <- read.table("UCI HAR Dataset/train/y_train.txt")
raw_y_test <- read.table("UCI HAR Dataset/test/y_test.txt")
raw_y <- rbind(raw_y_train,raw_y_test)
names(raw_y) <- c("activity_id")
activity_labels <- read.table("UCI HAR Dataset/activity_labels.txt")
names(activity_labels) <- c("activity_id","activity_name")
activity <- left_join(raw_y,activity_labels,by="activity_id")
unique(activity) %>% arrange(activity_id)
```

Now we are ready to combine the subject column, the activity columns and the main data set. We create a new column that combines the subject id with the activity id. This will be used later to calculate averages by subject and activity. We now have 10299 rows and 70 columns

``` {r subject_activity,echo=TRUE}
## add subject and activity columns to the data set
data <- cbind(subject,activity) %>% mutate(saID=paste(subject,activity_id,sep="_"))
data <- cbind(data,x)
dim(data)
str(data)
```

## Calculate averages by subject and activity

The final step is to calculate the average of each variable for each subject and each activity. This results in a tidy data set that has 30 * 6 = 180 rows and 70 columns, significantly smaller and easier to read and understand than the original raw data set.

``` {r calc_average,echo=TRUE}
by_subject_activity <- group_by(data,subject,activity_name)
mean_data <- summarise(by_subject_activity,activity_id = mean(activity_id))
mean_data <- mean_data %>% mutate(saID=paste(subject,activity_id,sep="_"))
for(x in mean_std_features) {
  t <- tapply(as.vector(data[,x]),data$saID,mean)
  t <- data.frame(names(t),as.vector(t))
  names(t) <- c("saID",x)
  t$saID <- as.character(t$saID)
  mean_data <- left_join(mean_data,t,by="saID")
}
mean_data <- arrange(mean_data,subject,activity_id)
mean_data
```

## Save tidy data set to file

The last step is to save the output tidy data set to a text file.

``` {r save_data,echo=TRUE}
write.table(mean_data,"out_mean_data.txt")
```
